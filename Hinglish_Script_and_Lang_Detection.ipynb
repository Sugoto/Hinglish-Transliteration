{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMJYvFeEM6DL5u6jPp5e/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sugoto/Indic-Language-NLP/blob/main/Hinglish_Script_and_Lang_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "uWhSME-TuoJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "sLTHlU9EkWIf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preModel = \"l3cube-pune/hing-bert-lid\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(preModel)\n",
        "model = AutoModelForTokenClassification.from_pretrained(preModel)\n",
        "classifier = pipeline(\"token-classification\", model=preModel)"
      ],
      "metadata": {
        "id": "5MgKq6d-Ym6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_font(text):\n",
        "    # Clean the input text\n",
        "    text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
        "    text = re.sub(r'\\\\n', ' ', text)\n",
        "    text = re.sub(r'[@]', ' ', text)\n",
        "    text = re.sub(r'[  ]', ' ', text)\n",
        "\n",
        "    # Detect script\n",
        "    is_english = any('a' <= char <= 'z' or 'A' <= char <= 'Z' for char in text)\n",
        "    is_hindi = any(char != \" \" and not ('a' <= char <= 'z' or 'A' <= char <= 'Z') for char in text)\n",
        "\n",
        "    if is_english and is_hindi:\n",
        "        script = \"Hinglish mixed\"\n",
        "    elif is_english and not is_hindi:\n",
        "        script = \"English\"\n",
        "    else:\n",
        "        script = \"Hindi\"\n",
        "\n",
        "    # Prepare the text for language detection\n",
        "    final_text = f'{text.lower()} [SEP]'\n",
        "\n",
        "    # Chunk the text into smaller segments\n",
        "    def get_chunks(s, max_length):\n",
        "        start = end = 0\n",
        "        while start + max_length < len(s) and end != -1:\n",
        "            end = s.rfind(\" \", start, start + max_length + 1)\n",
        "            yield s[start:end]\n",
        "            start = end + 1\n",
        "        yield s[start:]\n",
        "\n",
        "    # Detect the language of each chunk\n",
        "    chunks = get_chunks(final_text, 100)\n",
        "    chunk_arr = list(chunks)\n",
        "\n",
        "    word_count = hindi_count = english_count = 0\n",
        "\n",
        "\n",
        "    for ExampleText in chunkArr:\n",
        "\n",
        "        res = classifier(ExampleText)\n",
        "\n",
        "        fw = ''\n",
        "        si = 1\n",
        "        for i in range(len(res)):\n",
        "            sw = res[i]\n",
        "            word = re.sub(r'[#]', '', sw['word'])\n",
        "            if sw['index'] > 1:\n",
        "                if sw['start'] - res[i - 1]['end'] < 2:\n",
        "                    fw = fw + word\n",
        "                else:\n",
        "                    wordCount += 1\n",
        "                    lang = res[si]['entity']\n",
        "\n",
        "                    if (ord(fw[0]) > 125):\n",
        "                        lang = 'HI'\n",
        "                    if (lang == \"HI\"):\n",
        "                        hindiCount = hindiCount + 1\n",
        "                    else:\n",
        "                        engCount = engCount + 1\n",
        "                    fw = word\n",
        "                    si = i\n",
        "            else:\n",
        "                fw = word\n",
        "\n",
        "    lang = \"\"\n",
        "    if hindiCount and engCount:\n",
        "        lang = \"Hinglish mixed\"\n",
        "    elif hindiCount and not engCount:\n",
        "        lang = \"Hindi\"\n",
        "    else:\n",
        "        lang = \"English\"\n",
        "\n",
        "    print(f\"Script: {script}\")\n",
        "    print(f\"Language: {lang}\")\n",
        "    print(f'Total Number of words in the paragraph: {wordCount}')\n",
        "    print(f'Number of Hindi words in the paragraph: {hindiCount}')\n",
        "    print(f'Number of English words in the paragraph: {engCount}')\n",
        "\n",
        "    data = {'Hindi': hindiCount, 'English': engCount}\n",
        "    languages = list(data.keys())\n",
        "    wordcount = list(data.values())\n"
      ],
      "metadata": {
        "id": "rbpnY1GOlhit"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detectFont(\"mera naam kya hai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc9ZKnKZmVjO",
        "outputId": "bd829b82-05b1-4d07-c55d-c386fab1ab21"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script: English\n",
            "Language: Hinglish mixed\n",
            "Total Number of words in the paragraph: 3\n",
            "Number of Hindi words in the paragraph: 2\n",
            "Number of English words in the paragraph: 1\n"
          ]
        }
      ]
    }
  ]
}